# üöÄ Supabase Optimization Plan - Palm Island Repository

## Current State Analysis

### ‚úÖ What You Have
- Supabase project: `yvnuayzslukamizrlhwb.supabase.co`
- Basic client setup (`@supabase/supabase-js` v2.39.0)
- Schema file with 8 tables (`schema.sql`)
- Storage buckets in use: `story-images`, `story-videos`, `profile-images`
- SSR package installed but not utilized

### ‚ùå What's Missing/Broken
- **No Supabase CLI** ‚Üí Can't manage database locally or run migrations
- **No Auth Implementation** ‚Üí Can't secure data or track users
- **No Row Level Security (RLS)** ‚Üí Database is wide open or locked down
- **No TypeScript types** ‚Üí No autocomplete, prone to errors
- **Manual schema management** ‚Üí Hard to track changes or rollback
- **No local development** ‚Üí Can't test without hitting production DB
- **No storage policies** ‚Üí Buckets may not have proper access control
- **No migration system** ‚Üí Schema changes are untracked
- **Client/Server separation issues** ‚Üí Not using @supabase/ssr properly

---

## üéØ Optimization Plan - Priority Order

### Phase 1: Foundation (Week 1) ‚ö° HIGH PRIORITY

#### 1.1 Install & Configure Supabase CLI

**Why:** This unlocks everything else - local dev, migrations, type safety, and easy management.

**Steps:**

```bash
# Install Supabase CLI globally
npm install -g supabase

# Verify installation
supabase --version

# Navigate to project
cd /Users/tractor/palm-island-repository/web-platform

# Initialize Supabase in project
supabase init

# Link to your hosted project
supabase link --project-ref yvnuayzslukamizrlhwb
```

**What This Creates:**
```
web-platform/
‚îú‚îÄ‚îÄ supabase/
‚îÇ   ‚îú‚îÄ‚îÄ config.toml          # Project configuration
‚îÇ   ‚îú‚îÄ‚îÄ seed.sql             # Sample data for testing
‚îÇ   ‚îú‚îÄ‚îÄ migrations/          # Database version control
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 20241108_initial_schema.sql
‚îÇ   ‚îî‚îÄ‚îÄ functions/           # Edge Functions (optional)
```

**Benefits:**
- ‚úÖ Local Supabase instance for development
- ‚úÖ Migration tracking (like git for database)
- ‚úÖ Type generation from database schema
- ‚úÖ Easy backup/restore
- ‚úÖ Team collaboration on schema changes

---

#### 1.2 Convert Schema to Migration

**Why:** Your current `schema.sql` is untracked. Migrations version-control your database.

**Steps:**

```bash
# Create initial migration from your existing schema
supabase migration new initial_schema

# Copy your schema.sql content into the migration file
# File will be at: supabase/migrations/<timestamp>_initial_schema.sql
```

Then move your schema content:
```bash
cp web-platform/lib/empathy-ledger/schema.sql supabase/migrations/20241108000000_initial_schema.sql
```

**Apply migration to local dev database:**
```bash
supabase db reset  # Applies all migrations to local DB
```

**Apply to hosted Supabase:**
```bash
supabase db push  # Pushes migrations to production
```

**Benefits:**
- ‚úÖ Every schema change is tracked
- ‚úÖ Can rollback if needed
- ‚úÖ Team can see what changed and when
- ‚úÖ Automatic deployment pipeline possible

---

#### 1.3 Generate TypeScript Types

**Why:** Get autocomplete, catch errors at compile time, avoid typos.

**Steps:**

```bash
# Generate types from your database
supabase gen types typescript --local > lib/supabase/database.types.ts
```

**Update your client:**

```typescript
// lib/supabase/client.ts
import { createClient as createSupabaseClient } from '@supabase/supabase-js'
import { Database } from './database.types'

export function createClient() {
  return createSupabaseClient<Database>(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!
  )
}
```

**Now in your code:**

```typescript
// Before (no autocomplete, error-prone)
const { data } = await supabase.from('stories').select('title')

// After (full autocomplete!)
const { data } = await supabase
  .from('stories')  // ‚Üê Autocomplete shows all tables
  .select('title, content, storyteller_id')  // ‚Üê Autocomplete shows all fields!
```

**Benefits:**
- ‚úÖ Autocomplete for all tables and columns
- ‚úÖ Catch typos before runtime
- ‚úÖ Better developer experience
- ‚úÖ Refactoring is safer

---

### Phase 2: Authentication (Week 2) üîê HIGH PRIORITY

#### 2.1 Implement Supabase Auth

**Current Problem:** No user authentication, anyone can write to DB (or no one can).

**Solution:** Add Supabase Auth with Next.js App Router.

**Install Auth Helpers:**

```bash
cd web-platform
npm install @supabase/ssr @supabase/auth-helpers-nextjs
```

**Create proper client setup:**

```typescript
// lib/supabase/client.ts (Client Components)
import { createBrowserClient } from '@supabase/ssr'
import { Database } from './database.types'

export function createClient() {
  return createBrowserClient<Database>(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!
  )
}
```

```typescript
// lib/supabase/server.ts (Server Components)
import { createServerClient } from '@supabase/ssr'
import { cookies } from 'next/headers'
import { Database } from './database.types'

export async function createServerClient() {
  const cookieStore = await cookies()

  return createServerClient<Database>(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,
    {
      cookies: {
        get(name: string) {
          return cookieStore.get(name)?.value
        },
      },
    }
  )
}
```

```typescript
// lib/supabase/middleware.ts (Middleware for auth refresh)
import { createServerClient } from '@supabase/ssr'
import { NextResponse, type NextRequest } from 'next/server'

export async function updateSession(request: NextRequest) {
  let response = NextResponse.next({
    request: {
      headers: request.headers,
    },
  })

  const supabase = createServerClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,
    {
      cookies: {
        get(name: string) {
          return request.cookies.get(name)?.value
        },
        set(name: string, value: string, options: any) {
          request.cookies.set({ name, value, ...options })
          response = NextResponse.next({
            request: {
              headers: request.headers,
            },
          })
          response.cookies.set({ name, value, ...options })
        },
        remove(name: string, options: any) {
          request.cookies.set({ name, value: '', ...options })
          response = NextResponse.next({
            request: {
              headers: request.headers,
            },
          })
          response.cookies.set({ name, value: '', ...options })
        },
      },
    }
  )

  await supabase.auth.getUser()

  return response
}
```

```typescript
// middleware.ts (root of web-platform)
import { updateSession } from '@/lib/supabase/middleware'

export async function middleware(request: NextRequest) {
  return await updateSession(request)
}

export const config = {
  matcher: [
    '/((?!_next/static|_next/image|favicon.ico|.*\\.(?:svg|png|jpg|jpeg|gif|webp)$).*)',
  ],
}
```

**Add Login Page:**

```typescript
// app/login/page.tsx
'use client'

import { createClient } from '@/lib/supabase/client'
import { useRouter } from 'next/navigation'
import { useState } from 'react'

export default function LoginPage() {
  const [email, setEmail] = useState('')
  const [password, setPassword] = useState('')
  const router = useRouter()
  const supabase = createClient()

  async function handleLogin() {
    const { error } = await supabase.auth.signInWithPassword({
      email,
      password,
    })

    if (!error) {
      router.push('/admin/storytellers')
    }
  }

  async function handleSignUp() {
    const { error } = await supabase.auth.signUp({
      email,
      password,
    })

    if (!error) {
      alert('Check your email for confirmation link!')
    }
  }

  return (
    <div className="min-h-screen flex items-center justify-center bg-gradient-to-br from-blue-50 to-teal-50">
      <div className="bg-white p-8 rounded-xl shadow-lg max-w-md w-full">
        <h1 className="text-3xl font-bold mb-6">PICC Admin Login</h1>

        <input
          type="email"
          placeholder="Email"
          value={email}
          onChange={(e) => setEmail(e.target.value)}
          className="w-full px-4 py-2 border rounded-lg mb-4"
        />

        <input
          type="password"
          placeholder="Password"
          value={password}
          onChange={(e) => setPassword(e.target.value)}
          className="w-full px-4 py-2 border rounded-lg mb-4"
        />

        <button
          onClick={handleLogin}
          className="w-full bg-blue-600 text-white py-2 rounded-lg mb-2"
        >
          Login
        </button>

        <button
          onClick={handleSignUp}
          className="w-full bg-gray-200 text-gray-800 py-2 rounded-lg"
        >
          Sign Up
        </button>
      </div>
    </div>
  )
}
```

**Benefits:**
- ‚úÖ Secure user authentication
- ‚úÖ Email/password, magic links, OAuth (Google, GitHub, etc.)
- ‚úÖ Session management handled automatically
- ‚úÖ Can track who created/edited stories
- ‚úÖ Admin vs. public access control

---

#### 2.2 Enable Row Level Security (RLS)

**Critical:** Right now your data is either completely open or completely locked.

**Create RLS policies:**

```sql
-- Enable RLS on all tables
ALTER TABLE profiles ENABLE ROW LEVEL SECURITY;
ALTER TABLE stories ENABLE ROW LEVEL SECURITY;
ALTER TABLE story_media ENABLE ROW LEVEL SECURITY;

-- Public read access to published stories
CREATE POLICY "Public stories viewable by everyone"
ON stories FOR SELECT
USING (status = 'published' AND access_level = 'public');

-- Authenticated users can read community stories
CREATE POLICY "Community stories viewable by authenticated users"
ON stories FOR SELECT
USING (
  access_level IN ('public', 'community')
  AND status = 'published'
  AND auth.role() = 'authenticated'
);

-- Users can create stories
CREATE POLICY "Authenticated users can create stories"
ON stories FOR INSERT
WITH CHECK (auth.role() = 'authenticated');

-- Users can update their own stories
CREATE POLICY "Users can update own stories"
ON stories FOR UPDATE
USING (
  auth.uid() = (SELECT user_id FROM profiles WHERE id = stories.storyteller_id)
);

-- Admin users can do anything (requires adding is_admin flag to profiles)
CREATE POLICY "Admins can do anything"
ON stories
USING (
  EXISTS (
    SELECT 1 FROM profiles
    WHERE profiles.user_id = auth.uid()
    AND profiles.is_admin = true
  )
);
```

**Benefits:**
- ‚úÖ Database-level security (can't be bypassed)
- ‚úÖ Fine-grained access control
- ‚úÖ Protects against SQL injection
- ‚úÖ Works automatically with all client libraries

---

### Phase 3: Storage Optimization (Week 3) üìÅ

#### 3.1 Create & Configure Storage Buckets

**Current buckets needed:**
- `profile-images` - Profile photos
- `story-images` - Story photos
- `story-videos` - Story videos

**Set up via CLI:**

```bash
# Create buckets (if they don't exist)
supabase storage create profile-images --public
supabase storage create story-images --public
supabase storage create story-videos --public
```

**Configure bucket policies:**

```sql
-- Allow authenticated users to upload to profile-images
CREATE POLICY "Authenticated users can upload profile images"
ON storage.objects FOR INSERT
WITH CHECK (
  bucket_id = 'profile-images'
  AND auth.role() = 'authenticated'
);

-- Allow users to update their own profile image
CREATE POLICY "Users can update own profile image"
ON storage.objects FOR UPDATE
USING (
  bucket_id = 'profile-images'
  AND auth.uid() = owner
);

-- Public read access
CREATE POLICY "Public read access to profile images"
ON storage.objects FOR SELECT
USING (bucket_id = 'profile-images');

-- Similar policies for story-images and story-videos
CREATE POLICY "Authenticated users can upload story media"
ON storage.objects FOR INSERT
WITH CHECK (
  bucket_id IN ('story-images', 'story-videos')
  AND auth.role() = 'authenticated'
);

CREATE POLICY "Public read access to story media"
ON storage.objects FOR SELECT
USING (bucket_id IN ('story-images', 'story-videos'));
```

**Optimize uploads:**

```typescript
// lib/supabase/storage.ts
export async function uploadImage(
  bucket: string,
  path: string,
  file: File,
  options?: {
    cacheControl?: string
    upsert?: boolean
  }
) {
  const supabase = createClient()

  // Optimize image before upload (optional)
  const optimizedFile = await optimizeImage(file)

  const { data, error } = await supabase.storage
    .from(bucket)
    .upload(path, optimizedFile, {
      cacheControl: options?.cacheControl || '3600',
      upsert: options?.upsert || false,
    })

  if (error) throw error

  const { data: { publicUrl } } = supabase.storage
    .from(bucket)
    .getPublicUrl(path)

  return { path: data.path, publicUrl }
}

async function optimizeImage(file: File): Promise<File> {
  // Use browser APIs or a library to compress images
  // This reduces storage costs and improves load times
  return file // Placeholder
}
```

**Benefits:**
- ‚úÖ Organized file storage
- ‚úÖ Automatic CDN distribution
- ‚úÖ Image transformations on-the-fly
- ‚úÖ Proper access control
- ‚úÖ Cost-effective (only pay for what you use)

---

#### 3.2 Implement Image Transformations

**Supabase provides automatic image resizing/optimization:**

```typescript
// Instead of using raw publicUrl, use transformation URL
export function getOptimizedImageUrl(
  bucket: string,
  path: string,
  options: {
    width?: number
    height?: number
    quality?: number
    format?: 'origin' | 'webp'
  }
) {
  const supabase = createClient()

  const { data } = supabase.storage
    .from(bucket)
    .getPublicUrl(path, {
      transform: {
        width: options.width,
        height: options.height,
        quality: options.quality || 80,
        format: options.format || 'webp',
      },
    })

  return data.publicUrl
}

// Usage in components
<img
  src={getOptimizedImageUrl('story-images', story.image_path, {
    width: 800,
    quality: 85,
    format: 'webp'
  })}
  alt={story.title}
/>
```

**Benefits:**
- ‚úÖ Automatic image optimization
- ‚úÖ Faster page loads
- ‚úÖ Reduced bandwidth costs
- ‚úÖ No separate image processing service needed

---

### Phase 4: Developer Experience (Week 4) üíª

#### 4.1 Local Development Workflow

**Start local Supabase:**

```bash
# Start all Supabase services locally (Postgres, Auth, Storage, etc.)
supabase start

# This gives you:
# - Local PostgreSQL database
# - Local Auth server
# - Local Storage server
# - Studio UI at http://localhost:54323
```

**Your .env.local for development:**

```bash
# Local Supabase (when running supabase start)
NEXT_PUBLIC_SUPABASE_URL=http://localhost:54321
NEXT_PUBLIC_SUPABASE_ANON_KEY=<local_anon_key_from_supabase_start>

# Production Supabase (for deployment)
# NEXT_PUBLIC_SUPABASE_URL=https://yvnuayzslukamizrlhwb.supabase.co
# NEXT_PUBLIC_SUPABASE_ANON_KEY=<your_production_anon_key>
```

**Benefits:**
- ‚úÖ Test schema changes locally before production
- ‚úÖ Seed database with test data
- ‚úÖ No risk of breaking production
- ‚úÖ Works offline
- ‚úÖ Faster development (no network latency)

---

#### 4.2 Database Seeding

**Create seed data for testing:**

```sql
-- supabase/seed.sql

-- Seed profiles
INSERT INTO profiles (full_name, preferred_name, storyteller_type, is_elder, location)
VALUES
  ('Mary Wilson', 'Mary', 'elder', true, 'Palm Island'),
  ('John Smith', 'Johnny', 'youth', false, 'Palm Island'),
  ('Sarah Jones', 'Sarah', 'service_provider', false, 'Palm Island');

-- Seed stories
INSERT INTO stories (
  storyteller_id,
  title,
  content,
  story_type,
  category,
  status,
  access_level
)
SELECT
  p.id,
  'Traditional Fishing Knowledge',
  'Our elders taught us how to read the tides...',
  'elder_wisdom',
  'culture',
  'published',
  'public'
FROM profiles p
WHERE p.full_name = 'Mary Wilson'
LIMIT 1;
```

**Load seed data:**

```bash
supabase db reset  # Resets local DB and runs seed.sql
```

**Benefits:**
- ‚úÖ Consistent test data
- ‚úÖ Easy onboarding for new developers
- ‚úÖ Can test features without manual data entry

---

#### 4.3 Database Backups

**Automated backups:**

```bash
# Backup current database
supabase db dump -f backup.sql

# Backup specific tables
supabase db dump -f stories_backup.sql --data-only --schema public --table stories

# Restore from backup
psql <database_url> -f backup.sql
```

**Schedule regular backups** (add to package.json):

```json
{
  "scripts": {
    "db:backup": "supabase db dump -f backups/$(date +%Y%m%d_%H%M%S).sql",
    "db:restore": "supabase db reset"
  }
}
```

**Benefits:**
- ‚úÖ Disaster recovery
- ‚úÖ Can test risky migrations with rollback option
- ‚úÖ Peace of mind

---

### Phase 5: Performance & Monitoring (Week 5) üìä

#### 5.1 Add Database Indexes

**Check your current queries and add indexes:**

```sql
-- supabase/migrations/<timestamp>_add_indexes.sql

-- Index for filtering published stories
CREATE INDEX idx_stories_status_access ON stories(status, access_level);

-- Index for storyteller lookups
CREATE INDEX idx_stories_storyteller ON stories(storyteller_id);

-- Index for date sorting
CREATE INDEX idx_stories_created_at ON stories(created_at DESC);

-- Index for category filtering
CREATE INDEX idx_stories_category ON stories(category);

-- Composite index for common query patterns
CREATE INDEX idx_stories_published_public
ON stories(status, access_level, created_at DESC)
WHERE status = 'published' AND access_level = 'public';

-- Full-text search index
CREATE INDEX idx_stories_fulltext ON stories
USING GIN(to_tsvector('english', title || ' ' || content));
```

**Benefits:**
- ‚úÖ 10-100x faster queries
- ‚úÖ Better user experience
- ‚úÖ Lower database costs

---

#### 5.2 Enable Realtime (Optional)

**For live updates when stories are added:**

```typescript
// In your stories page
useEffect(() => {
  const supabase = createClient()

  const channel = supabase
    .channel('stories-changes')
    .on(
      'postgres_changes',
      {
        event: 'INSERT',
        schema: 'public',
        table: 'stories',
        filter: 'status=eq.published'
      },
      (payload) => {
        console.log('New story published!', payload.new)
        // Add to your stories list
        setStories((prev) => [payload.new, ...prev])
      }
    )
    .subscribe()

  return () => {
    supabase.removeChannel(channel)
  }
}, [])
```

**Benefits:**
- ‚úÖ Live updates without polling
- ‚úÖ Better UX for admin dashboards
- ‚úÖ Real-time collaboration

---

#### 5.3 Add Query Optimization

**Use React Query for caching:**

```typescript
// lib/hooks/useStories.ts
import { useQuery } from '@tanstack/react-query'
import { createClient } from '@/lib/supabase/client'

export function useStories() {
  return useQuery({
    queryKey: ['stories'],
    queryFn: async () => {
      const supabase = createClient()
      const { data, error } = await supabase
        .from('stories')
        .select('*, storyteller:storyteller_id(*)')
        .eq('status', 'published')
        .eq('access_level', 'public')
        .order('created_at', { ascending: false })

      if (error) throw error
      return data
    },
    staleTime: 60000, // Cache for 1 minute
  })
}

// In your component
const { data: stories, isLoading } = useStories()
```

**Benefits:**
- ‚úÖ Automatic caching
- ‚úÖ Fewer database queries
- ‚úÖ Optimistic updates
- ‚úÖ Better performance

---

### Phase 6: Advanced Features (Week 6+) üöÄ

#### 6.1 Edge Functions

**For server-side operations:**

```bash
# Create an edge function
supabase functions new story-analyzer

# Edit the function
# supabase/functions/story-analyzer/index.ts
```

```typescript
import { serve } from 'https://deno.land/std@0.168.0/http/server.ts'
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'

serve(async (req) => {
  const { storyId } = await req.json()

  const supabase = createClient(
    Deno.env.get('SUPABASE_URL')!,
    Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!
  )

  // Analyze story sentiment, extract keywords, etc.
  const { data: story } = await supabase
    .from('stories')
    .select('content')
    .eq('id', storyId)
    .single()

  // Run AI analysis
  const keywords = await extractKeywords(story.content)

  // Update story
  await supabase
    .from('stories')
    .update({ keywords })
    .eq('id', storyId)

  return new Response(JSON.stringify({ keywords }), {
    headers: { 'Content-Type': 'application/json' },
  })
})
```

**Deploy:**

```bash
supabase functions deploy story-analyzer
```

**Use cases:**
- ‚úÖ AI-powered story analysis
- ‚úÖ Automated tagging
- ‚úÖ Email notifications
- ‚úÖ PDF generation for reports
- ‚úÖ Data processing pipelines

---

#### 6.2 Database Functions

**Create reusable database functions:**

```sql
-- supabase/migrations/<timestamp>_create_functions.sql

-- Function to get storyteller stats
CREATE OR REPLACE FUNCTION get_storyteller_stats(storyteller_uuid UUID)
RETURNS TABLE (
  total_stories INTEGER,
  published_stories INTEGER,
  total_views INTEGER,
  avg_views NUMERIC
) AS $$
BEGIN
  RETURN QUERY
  SELECT
    COUNT(*)::INTEGER,
    COUNT(*) FILTER (WHERE status = 'published')::INTEGER,
    COALESCE(SUM(views), 0)::INTEGER,
    COALESCE(AVG(views), 0)::NUMERIC
  FROM stories
  WHERE storyteller_id = storyteller_uuid;
END;
$$ LANGUAGE plpgsql;
```

**Call from client:**

```typescript
const { data, error } = await supabase.rpc('get_storyteller_stats', {
  storyteller_uuid: storytellerId
})
```

**Benefits:**
- ‚úÖ Complex queries run on database (faster)
- ‚úÖ Reusable logic
- ‚úÖ Better security (business logic stays in DB)

---

## üìã Implementation Checklist

### Week 1: Foundation ‚ö°
- [ ] Install Supabase CLI (`npm install -g supabase`)
- [ ] Initialize project (`supabase init`)
- [ ] Link to hosted project (`supabase link`)
- [ ] Convert schema to migration
- [ ] Generate TypeScript types
- [ ] Test local development (`supabase start`)

### Week 2: Authentication üîê
- [ ] Update client libraries (`@supabase/ssr`)
- [ ] Create proper client/server setup
- [ ] Add login page
- [ ] Implement RLS policies
- [ ] Add admin flag to profiles table
- [ ] Test authentication flow

### Week 3: Storage üìÅ
- [ ] Create/verify storage buckets
- [ ] Set up storage policies
- [ ] Implement image upload helper
- [ ] Add image transformations
- [ ] Test upload/download flow

### Week 4: Developer Experience üíª
- [ ] Set up local development workflow
- [ ] Create seed.sql with test data
- [ ] Add backup scripts to package.json
- [ ] Document onboarding process
- [ ] Train team on new workflow

### Week 5: Performance üìä
- [ ] Add database indexes
- [ ] Implement React Query
- [ ] Set up error tracking (Sentry)
- [ ] Add performance monitoring
- [ ] Optimize slow queries

### Week 6: Advanced (Optional) üöÄ
- [ ] Create edge functions as needed
- [ ] Add database functions for complex queries
- [ ] Enable realtime subscriptions
- [ ] Set up automated testing

---

## üõ†Ô∏è Recommended Tools

### Essential
- **Supabase CLI** - Database management
- **Supabase Studio** - Visual database editor (http://localhost:54323)
- **VS Code Extension** - SQL formatting and autocomplete
- **React Query** - Client-side caching

### Nice to Have
- **Prisma** - Type-safe ORM (alternative to raw SQL)
- **Zod** - Runtime type validation
- **Sentry** - Error tracking
- **Posthog** - Product analytics

---

## üí∞ Cost Optimization

### Free Tier Limits (what you get for free)
- 500 MB database
- 1 GB file storage
- 2 GB bandwidth
- 50 MB database backups
- 50,000 monthly active users (Auth)

### Tips to Stay in Free Tier
- ‚úÖ Use image transformations (reduces storage)
- ‚úÖ Enable compression on uploads
- ‚úÖ Set cache headers on storage files
- ‚úÖ Use indexes to reduce query costs
- ‚úÖ Clean up old draft stories periodically

### When to Upgrade ($25/month Pro plan)
- Need more than 500 MB database
- Need more than 1 GB file storage
- Want daily backups (automatic)
- Need point-in-time recovery

---

## üÜò Common Issues & Solutions

### Issue: "Missing Supabase environment variables"
**Solution:** Copy `.env.local.example` to `.env.local` and fill in values

### Issue: RLS blocking all queries
**Solution:** Check policies allow your use case, or temporarily disable RLS during development

### Issue: File uploads failing
**Solution:** Check storage policies and bucket existence

### Issue: Slow queries
**Solution:** Add indexes (see Phase 5)

### Issue: Type errors after schema changes
**Solution:** Regenerate types with `supabase gen types typescript`

---

## üìö Learning Resources

- [Supabase Docs](https://supabase.com/docs)
- [Next.js + Supabase Tutorial](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs)
- [Row Level Security Guide](https://supabase.com/docs/guides/auth/row-level-security)
- [Storage Guide](https://supabase.com/docs/guides/storage)
- [YouTube: Supabase Crash Course](https://www.youtube.com/results?search_query=supabase+crash+course)

---

## üéØ Success Metrics

After implementation, you should have:
- ‚úÖ Local development environment
- ‚úÖ Version-controlled database schema
- ‚úÖ Type-safe database queries
- ‚úÖ Secure authentication
- ‚úÖ Properly configured storage
- ‚úÖ Fast, indexed queries
- ‚úÖ Team-friendly workflow

---

## Next Steps

**Start with Week 1 tasks** - Everything else builds on the foundation. Once you have CLI set up and migrations working, the rest becomes much easier.

**Questions?** Check the Supabase Discord or documentation - the community is very helpful!
